{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1dc3e75",
   "metadata": {},
   "source": [
    "### Consigna del desafío 1\n",
    "\n",
    "**1**. Vectorizar documentos. Tomar 5 documentos al azar y medir similaridad con el resto de los documentos.\n",
    "Estudiar los 5 documentos más similares de cada uno analizar si tiene sentido\n",
    "la similaridad según el contenido del texto y la etiqueta de clasificación.\n",
    "\n",
    "**2**. Construir un modelo de clasificación por prototipos (tipo zero-shot). Clasificar los documentos de un conjunto de test comparando cada uno con todos los de entrenamiento y asignar la clase al label del documento del conjunto de entrenamiento con mayor similaridad.\n",
    "\n",
    "**3**. Entrenar modelos de clasificación Naïve Bayes para maximizar el desempeño de clasificación\n",
    "(f1-score macro) en el conjunto de datos de test. Considerar cambiar parámteros\n",
    "de instanciación del vectorizador y los modelos y probar modelos de Naïve Bayes Multinomial\n",
    "y ComplementNB.\n",
    "\n",
    "**4**. Transponer la matriz documento-término. De esa manera se obtiene una matriz\n",
    "término-documento que puede ser interpretada como una colección de vectorización de palabras.\n",
    "Estudiar ahora similaridad entre palabras tomando 5 palabras y estudiando sus 5 más similares. **La elección de palabras no debe ser al azar para evitar la aparición de términos poco interpretables, elegirlas \"manualmente\"**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8addddfb",
   "metadata": {},
   "source": [
    "#### Parte 1\n",
    "#### Vectorizar y medir similaridad para 5 documentos al azar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "397af8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================\n",
      "Documento elegido (índice): 8754\n",
      "Etiqueta: talk.religion.misc\n",
      "Fragmento del documento (primeros 400 caracteres):\n",
      "/(hudson) /If someone inflicts pain on themselves, whether they enjoy it or not, they /are hurting themselves.  They may be permanently damaging their body.  That is true.  It is also none of your business.    Some people may also reason that by reading the bible and being a Xtian you are permanently damaging your brain.  By your logic, it would be OK for them to come into your home, take away yo\n",
      "--------------------------------------------------------------\n",
      "5 documentos más similares (índice, etiqueta, puntaje, fragmento):\n",
      "\n",
      "- Índice: 6552\n",
      "  Etiqueta: talk.religion.misc\n",
      "  Similaridad (coseno): 0.4904\n",
      "  Fragmento: If I have a habit that I really want to break, and I am willing to make whatever sacrifice I need to make to break it, then I do so. There have been bad habits of mine that I've decided to put forth the effort to break, and I've done so; there have been other bad habits that I've decided are not wo\n",
      "\n",
      "- Índice: 10613\n",
      "  Etiqueta: talk.religion.misc\n",
      "  Similaridad (coseno): 0.4812\n",
      "  Fragmento: /(hudson) /Yes you do.  Who is to say that it is immoral for onesself to experience /pain or to be hurt in some other way.  Maybe unpleasant, but that doesn't /say anything about morality.  It violates free will, Hudson.    (me)  /(hudson) /Why is making someone a less productive member of society i\n",
      "\n",
      "- Índice: 3616\n",
      "  Etiqueta: talk.religion.misc\n",
      "  Similaridad (coseno): 0.4653\n",
      "  Fragmento: And I maintain:  Some people do not want to enter into the light and the knowledge that they alone are their own masters, because they fear it; they are too afraid of having to face the world on their own terms.  And so, by their own choice, they will remain in darkness, sort of like bugs under a r\n",
      "\n",
      "- Índice: 8726\n",
      "  Etiqueta: talk.politics.mideast\n",
      "  Similaridad (coseno): 0.4599\n",
      "  Fragmento: [After a small refresh Hasan got on the track again.]        |>    |> I get the impression Hasan realized he goofed and is now    |>    |> trying to drop the thread. Let him. It might save some    |>    |> miniscule portion of his sorry face.     |>    Not really. since i am a logical person who l\n",
      "\n",
      "- Índice: 3902\n",
      "  Etiqueta: talk.religion.misc\n",
      "  Similaridad (coseno): 0.4591\n",
      "  Fragmento: Are you your own master?  Do you have any habits that you cannot break? For one, you seem unable to master your lack of desire to understand even the slightest concept of the Bible.  Seems that ignorance has you mastered.  How about sexual sins?  Gotta any of those secret desires in your head tha\n",
      "==============================================================\n",
      "\n",
      "==============================================================\n",
      "Documento elegido (índice): 4965\n",
      "Etiqueta: comp.sys.mac.hardware\n",
      "Fragmento del documento (primeros 400 caracteres):\n",
      "No.  Plug the printer in the printer port, and the modem in the modem port. ;)\n",
      "--------------------------------------------------------------\n",
      "5 documentos más similares (índice, etiqueta, puntaje, fragmento):\n",
      "\n",
      "- Índice: 5830\n",
      "  Etiqueta: comp.sys.mac.hardware\n",
      "  Similaridad (coseno): 0.3653\n",
      "  Fragmento: Battery powered devices like the PowerBook are sometimes more sensitive to  serial port weirdness.  I had trouble with connecting my Mac Plus to an HP 95LX handheld.  Everything else worked okay on that port, but not the HP. (it runs on two penlite batteries).  It turned out that the plus (by accid\n",
      "\n",
      "- Índice: 9736\n",
      "  Etiqueta: comp.sys.mac.hardware\n",
      "  Similaridad (coseno): 0.3611\n",
      "  Fragmento: I have used both my serial ports with a modem and a serial printer,  so I cannot use Appletalk.  Is there a Ethernet to Localtalk hardware that will let me use the Ethernet port on my Q700 as a Localtalk  port.  Until they come out with satellite dishes that sit on your window & give you internet ac\n",
      "\n",
      "- Índice: 1822\n",
      "  Etiqueta: comp.sys.ibm.pc.hardware\n",
      "  Similaridad (coseno): 0.3554\n",
      "  Fragmento: Can anybody please help me with information on the use of the bi-directional printer port.  I have successfully used one on a Toshiba laptop by enabling bit 0 of port 0x37f and controlling bit 7 of port 0x37a for the direction of data flow (ie \"0\" for output, \"1\" for input).  The same code does not\n",
      "\n",
      "- Índice: 2327\n",
      "  Etiqueta: comp.sys.ibm.pc.hardware\n",
      "  Similaridad (coseno): 0.3407\n",
      "  Fragmento: With a sound card on interrupt 5, two serial ports (one for modem on i4, one for Miracle Piano on i3) and a printer port on i7, I have run out of low interrupts.  What I would like is a mouse port with an interrupt of 10, 11, or 12 (which ever interrupt the PS/2 mouse port uses) in in ISA i486 compu\n",
      "\n",
      "- Índice: 3408\n",
      "  Etiqueta: comp.graphics\n",
      "  Similaridad (coseno): 0.3405\n",
      "  Fragmento: Printer model and specification:  Canon CLC 500 (Color Laser Copier) ps-ipu unit (postscript intelligent processing unit)   Hello,  We have recently purchased a very expensive and nice color copier/printer.  We want to be able to print to it from our SGI iris network.  The  copier/printer has both a\n",
      "==============================================================\n",
      "\n",
      "==============================================================\n",
      "Documento elegido (índice): 7404\n",
      "Etiqueta: comp.os.ms-windows.misc\n",
      "Fragmento del documento (primeros 400 caracteres):\n",
      "Hello.        Is it possible to know minimize program manager when starting an       application and to restore it when the application is ended ?       If possible, please tell me how to do it !\n",
      "--------------------------------------------------------------\n",
      "5 documentos más similares (índice, etiqueta, puntaje, fragmento):\n",
      "\n",
      "- Índice: 342\n",
      "  Etiqueta: comp.windows.x\n",
      "  Similaridad (coseno): 0.2683\n",
      "  Fragmento: I need to have PCs and SPARCstations run the same application ( namely MicroSoft Project ). The original system ran on the PC. Now it needs to be expanded to allow UNIX users to work with the application. The current proposal is to use DESQview/X as a display server for the application.  I would lik\n",
      "\n",
      "- Índice: 896\n",
      "  Etiqueta: comp.windows.x\n",
      "  Similaridad (coseno): 0.2298\n",
      "  Fragmento: What \"it may think is right\" may be exactly what the user wants. Assuming that your application \"has reason to know better\" is, IMHO, anti-social.  If I start your application with a -geometry option are you going to ignore that as well?  There's really no way to force a window manager to do much\n",
      "\n",
      "- Índice: 8719\n",
      "  Etiqueta: sci.med\n",
      "  Similaridad (coseno): 0.2249\n",
      "  Fragmento: Hello,\n",
      "\n",
      "- Índice: 2429\n",
      "  Etiqueta: comp.graphics\n",
      "  Similaridad (coseno): 0.2249\n",
      "  Fragmento: Hello,\n",
      "\n",
      "- Índice: 7327\n",
      "  Etiqueta: comp.windows.x\n",
      "  Similaridad (coseno): 0.2219\n",
      "  Fragmento: I'm writing an application running under X (using Motif), and I need to do some stuff when the application quits.  Now, when I shut down my X Windows session, it doesn't seem to send a SIGTERM (or whatever) signal to my application (I'm trapping various signals like that).  Therefore, I thought I co\n",
      "==============================================================\n",
      "\n",
      "==============================================================\n",
      "Documento elegido (índice): 1009\n",
      "Etiqueta: talk.politics.guns\n",
      "Fragmento del documento (primeros 400 caracteres):\n",
      "[followups to talk.politics.guns]  rl> Russell Lawrence kr> Karl Rominger  kr> I support the right of any citizen with out a criminal history to own and     use firearms, regardless of race, gender, and RELIGION.  rl> Thanks for admitting that you, yourself, adhere to an illogical dogma.    Well, folks in t.p.guns, want to show how Russell's \"illogical dogma\" is   wrong?\n",
      "--------------------------------------------------------------\n",
      "5 documentos más similares (índice, etiqueta, puntaje, fragmento):\n",
      "\n",
      "- Índice: 1322\n",
      "  Etiqueta: talk.politics.guns\n",
      "  Similaridad (coseno): 0.1465\n",
      "  Fragmento: >This argument sounds very stupid.. if the ability to make guns from  >\"simple metalworking\" was easy,  then Drug dealers would make their own   >wouldn't they???.. why spend hundreds of dollars buying a gun that  >somebody else made cheap and is selling it to you at an  >exorbitant markup???... Th\n",
      "\n",
      "- Índice: 7162\n",
      "  Etiqueta: talk.politics.guns\n",
      "  Similaridad (coseno): 0.1458\n",
      "  Fragmento: Gun clubs: If you are a member you CAN borrow weapons....(Suprised??) You are supposed to train with a .22 for the 6 months, THEN you can start with anything bigger.  Drivers licence: Forgot that USA is THE land of cars..... Getting one in Scandinavia (and northern europe) is not easy. Average time\n",
      "\n",
      "- Índice: 5084\n",
      "  Etiqueta: alt.atheism\n",
      "  Similaridad (coseno): 0.1441\n",
      "  Fragmento: : Regardless of people's hidden motivations, the stated reasons for many : wars include religion.  Of course you can always claim that the REAL : reason was economics, politics, ethnic strife, or whatever.  But the : fact remains that the justification for many wars has been to conquer : the heathe\n",
      "\n",
      "- Índice: 9620\n",
      "  Etiqueta: talk.politics.guns\n",
      "  Similaridad (coseno): 0.1435\n",
      "  Fragmento: 1. Make a new Newsgroup called talk.politics.guns.PARANOID or  \ttalk.politics.guns.THEY'R.HERE.TO.TAKE.ME.AWAY  \t2. Move all postings about waco and burn to (guess where)..  \t3. Stop posting #### on this newsgroup  \tWe are all SO glad you're trying to save us from the evil  \tgoverment, but would you\n",
      "\n",
      "- Índice: 2358\n",
      "  Etiqueta: talk.politics.guns\n",
      "  Similaridad (coseno): 0.1392\n",
      "  Fragmento: / iftccu:talk.politics.guns / hays@ssd.intel.com (Kirk Hays) /    3:31 pm  Apr 13, 1993 /      >Some of the pro-gun posters in this group own no guns.  The dread    >\"Terminator\", aka \"The Rifleman\", owned no firearms for several    >years while posting in this group, as an example.  There are    >o\n",
      "==============================================================\n",
      "\n",
      "==============================================================\n",
      "Documento elegido (índice): 4899\n",
      "Etiqueta: sci.crypt\n",
      "Fragmento del documento (primeros 400 caracteres):\n",
      "...  Haven't you read any of Noam Chomsky's works? A widely used information net outside the control of the 'right people' is unthinkable. Hundreds of billions of dollars will be spent to wipe it out, sorry, 'regulate and order it' once the major media and poitical powers wake up to the efect it can have.  If you can't be bothered reading, get the video \"Manufacturing Consent\".\n",
      "--------------------------------------------------------------\n",
      "5 documentos más similares (índice, etiqueta, puntaje, fragmento):\n",
      "\n",
      "- Índice: 8726\n",
      "  Etiqueta: talk.politics.mideast\n",
      "  Similaridad (coseno): 0.1965\n",
      "  Fragmento: [After a small refresh Hasan got on the track again.]        |>    |> I get the impression Hasan realized he goofed and is now    |>    |> trying to drop the thread. Let him. It might save some    |>    |> miniscule portion of his sorry face.     |>    Not really. since i am a logical person who l\n",
      "\n",
      "- Índice: 5856\n",
      "  Etiqueta: sci.crypt\n",
      "  Similaridad (coseno): 0.1950\n",
      "  Fragmento: Thanks for posting this and making it available. This post will be LONG, I will comment on most of it, and am reluctantly leaving all of the original in place to provide context.  Please note that an alt. group has been set up for the Clipper stuff.\n",
      "\n",
      "- Índice: 913\n",
      "  Etiqueta: alt.atheism\n",
      "  Similaridad (coseno): 0.1879\n",
      "  Fragmento: The recent rise of nostalgia in this group, combined with the   incredible level of utter bullshit, has prompted me to comb   through my archives and pull out some of \"The Best of Alt.Atheism\"   for your reading pleasure.  I'll post a couple of these a day   unless group concensus demands that I sto\n",
      "\n",
      "- Índice: 10241\n",
      "  Etiqueta: sci.crypt\n",
      "  Similaridad (coseno): 0.1875\n",
      "  Fragmento: Read it again yourself, then re-apply the admonition you gave to the previous poster to yourself, as well.  The first clause is not a condition, it is a reason for explicitly supporting the right WHICH EXISTS, MILITIA OR NOT, that the people have a right to keep and bear arms.  This is NOT a right\n",
      "\n",
      "- Índice: 9115\n",
      "  Etiqueta: sci.crypt\n",
      "  Similaridad (coseno): 0.1875\n",
      "  Fragmento: It is incompetent, like almost anything you have posted here, so you'll be flamed, sorry.   %/$( your \"20 years of background in two Fortune 50 companies\"; I've lived 30 years under a totalitarian regime, and boy, I *can* recognize a totalitarian plot when I see one...   I am sure that -you- would\n",
      "==============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# 1) Cargar datos\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "y_train = newsgroups_train.target\n",
    "target_names = newsgroups_train.target_names\n",
    "docs = newsgroups_train.data\n",
    "\n",
    "# 2) Vectorizar con TfidfVectorizer\n",
    "tfidfvect = TfidfVectorizer()\n",
    "X_train = tfidfvect.fit_transform(docs)\n",
    "\n",
    "# 3) Seleccionar 5 documentos al azar (fijo semilla para reproducibilidad)\n",
    "rng = np.random.default_rng(42)\n",
    "n_docs = X_train.shape[0]\n",
    "chosen_idxs = rng.choice(n_docs, size=5, replace=False)\n",
    "\n",
    "# 4) Para cada documento elegido, medir similaridad coseno con todo el train\n",
    "top_k = 6  # pedimos 6 para luego eliminar el mismo documento y quedarnos con 5 similares\n",
    "for idx in chosen_idxs:\n",
    "    print(\"==============================================================\")\n",
    "    print(f\"Documento elegido (índice): {idx}\")\n",
    "    print(f\"Etiqueta: {target_names[y_train[idx]]}\")\n",
    "    print(\"Fragmento del documento (primeros 400 caracteres):\")\n",
    "    print(docs[idx][:400].strip().replace(\"\\n\", \" \"))\n",
    "    print(\"--------------------------------------------------------------\")\n",
    "    # calcular similaridad coseno entre este doc y todos\n",
    "    cossim = cosine_similarity(X_train[idx], X_train)[0]\n",
    "    # obtener índices ordenados de mayor a menor similaridad\n",
    "    sorted_idxs = np.argsort(cossim)[::-1]\n",
    "    # excluir el propio documento (aparece primero con similitud 1.0)\n",
    "    most_similar = [i for i in sorted_idxs if i != idx][:5]\n",
    "    print(\"5 documentos más similares (índice, etiqueta, puntaje, fragmento):\")\n",
    "    for sim_idx in most_similar:\n",
    "        print(f\"\\n- Índice: {sim_idx}\")\n",
    "        print(f\"  Etiqueta: {target_names[y_train[sim_idx]]}\")\n",
    "        print(f\"  Similaridad (coseno): {cossim[sim_idx]:.4f}\")\n",
    "        snippet = docs[sim_idx][:300].strip().replace(\"\\n\", \" \")\n",
    "        print(f\"  Fragmento: {snippet}\")\n",
    "    print(\"==============================================================\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f559d2b6",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "\n",
    "- En el doc 8754 (talk.religion.misc), casi todos los doc más similares también son talk.religion.misc,apareció un talk.politics.mideast, el texto es bastante similar a los otros con la diferencia que mezcla religión y política.\n",
    "\n",
    "- En el doc 4965 (comp.sys.mac.hardware), los doc más similares son del mismo grupo (Mac hardware), aunque también aparecen algunos de PC hardware, lo cual también tiene sentido porque se habla del mismo tema \"puertos de una impresora\".\n",
    "\n",
    "- En el doc 7404 (comp.os.ms-windows.misc), los doc más similares son de comp.windows.x, o sea, siguen siendo temas de sistemas de ventanas y aplicaciones.\n",
    "\n",
    "- En el doc 1009 (talk.politics.guns), casi todos los doc más similares son también de talk.politics.guns, salvo un doc de alt.atheism, que trata el mismo tema pero relacionando la política y religión.\n",
    "\n",
    "- En el doc 4899 (sci.crypt), varios de los doc más similares son sci.crypt, pero también aparecen talk.politics.mideast o alt.atheism, porque algunos textos tocan temas de política o sociedad en publicaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02034b0c",
   "metadata": {},
   "source": [
    "#### Parte 2\n",
    "#### Clasificación por prototipos (zero-shot style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ded08e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score (macro) del clasificador por prototipos: 0.5049911553681621\n",
      "--------------------------------------------------\n",
      "Texto test:\n",
      "I am a little confused on all of the models of the 88-89 bonnevilles. I have heard of the LE SE LSE SSE SSEI. Could someone tell me the differences are far as features or performance. I am also curious to know what the book value is for prefereably the 89 model. And how much less than book value can\n",
      "\n",
      "Etiqueta real: rec.autos\n",
      "Etiqueta predicha: alt.atheism\n",
      "--------------------------------------------------\n",
      "Texto test:\n",
      "I'm not familiar at all with the format of these \"X-Face:\" thingies, but after seeing them in some folks' headers, I've *got* to *see* them (and maybe make one of my own)!  I've got \"dpg-view\" on my Linux box (which displays \"uncompressed X-Faces\") and I've managed to compile [un]compface too... but\n",
      "\n",
      "Etiqueta real: comp.windows.x\n",
      "Etiqueta predicha: talk.religion.misc\n",
      "--------------------------------------------------\n",
      "Texto test:\n",
      " In a word, yes. \n",
      "\n",
      "Etiqueta real: alt.atheism\n",
      "Etiqueta predicha: talk.politics.mideast\n",
      "--------------------------------------------------\n",
      "Texto test:\n",
      " They were attacking the Iraqis to drive them out of Kuwait, a country whose citizens have close blood and business ties to Saudi citizens.  And me thinks if the US had not helped out the Iraqis would have swallowed Saudi Arabia, too (or at  least the eastern oilfields).  And no Muslim country was d\n",
      "\n",
      "Etiqueta real: talk.politics.mideast\n",
      "Etiqueta predicha: talk.politics.mideast\n",
      "--------------------------------------------------\n",
      "Texto test:\n",
      " I've just spent two solid months arguing that no such thing as an objective moral system exists.\n",
      "\n",
      "Etiqueta real: talk.religion.misc\n",
      "Etiqueta predicha: alt.atheism\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# 1) Cargar datos train y test\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "X_train_texts, y_train = newsgroups_train.data, newsgroups_train.target\n",
    "X_test_texts, y_test = newsgroups_test.data, newsgroups_test.target\n",
    "target_names = newsgroups_train.target_names\n",
    "\n",
    "# 2) Vectorizar con TF-IDF (entrenar solo en train)\n",
    "tfidfvect = TfidfVectorizer()\n",
    "X_train = tfidfvect.fit_transform(X_train_texts)\n",
    "X_test = tfidfvect.transform(X_test_texts)\n",
    "\n",
    "# 3) Clasificación por prototipos:\n",
    "# para cada documento de test buscamos el train más similar\n",
    "y_pred = []\n",
    "for i in range(X_test.shape[0]):\n",
    "    # similaridad con todos los documentos de train\n",
    "    sims = cosine_similarity(X_test[i], X_train)[0]\n",
    "    # índice del más similar\n",
    "    best_idx = np.argmax(sims)\n",
    "    # asignamos su etiqueta\n",
    "    y_pred.append(y_train[best_idx])\n",
    "\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# 4) Evaluar desempeño con F1-score macro\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "print(\"F1-score (macro) del clasificador por prototipos:\", f1_macro)\n",
    "\n",
    "# Mostrar primeras 5 predicciones vs reales\n",
    "for i in range(5):\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Texto test:\")\n",
    "    print(X_test_texts[i][:300].replace(\"\\n\",\" \"))\n",
    "    print(f\"\\nEtiqueta real: {target_names[y_test[i]]}\")\n",
    "    print(f\"Etiqueta predicha: {target_names[y_pred[i]]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dce97f",
   "metadata": {},
   "source": [
    "Conclusiones:\n",
    "\n",
    "- El F1-score no es muy alto (0.50), lo cual es esperado porque este método es bastante simple.\n",
    "\n",
    "- Los errores que muestra (ej. confundir rec.autos con alt.atheism) tienen sentido porque:\n",
    "\n",
    "    - El método depende únicamente de la similaridad semántica superficial (bolsa de palabras), sin contexto profundo.\n",
    "\n",
    "    - Si hay mucho vocabulario común entre categorías distintas, puede equivocarse.\n",
    "\n",
    "    - En la salida también se ve que en algunos casos acierta, como en talk.politics.mideast."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b12ee59",
   "metadata": {},
   "source": [
    "#### Parte 3\n",
    "#### Entrenar modelos de clasificación Naïve Bayes para maximizar el desempeño de clasificación\n",
    "#### (f1-score macro) en el conjunto de datos de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0745286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score (macro) MultinomialNB: 0.5854345727938506\n"
     ]
    }
   ],
   "source": [
    "# Prueba 1: Entrenar un MultinomialNB básico y evaluarlo\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Entrenar MultinomialNB\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "# Evaluación\n",
    "f1_nb = f1_score(y_test, y_pred_nb, average=\"macro\")\n",
    "print(\"F1-score (macro) MultinomialNB:\", f1_nb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31dda316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score (macro) ComplementNB: 0.692953349950875\n"
     ]
    }
   ],
   "source": [
    "# Prueba 2: ComplementNB baseline\n",
    "\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "cnb = ComplementNB()\n",
    "cnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_cnb = cnb.predict(X_test)\n",
    "f1_cnb = f1_score(y_test, y_pred_cnb, average='macro')\n",
    "print(\"F1-score (macro) ComplementNB:\", f1_cnb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4aff0a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'cnb__alpha': 0.1, 'tfidf__min_df': 1, 'tfidf__ngram_range': (1, 2)}\n",
      "Mejor F1-score (validación): 0.7666500125099275\n",
      "F1-score (macro) en test con mejor modelo: 0.7097526747834789\n"
     ]
    }
   ],
   "source": [
    "# Prueba 3: Grid Search para Naive Bayes\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Creamos pipeline: vectorizador + modelo\n",
    "pipeline_cnb = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "    ('cnb', ComplementNB())\n",
    "])\n",
    "\n",
    "# Definimos rejilla de parámetros\n",
    "param_grid = {\n",
    "    'tfidf__ngram_range': [(1,1), (1,2)],   # unigramas y bigramas\n",
    "    'tfidf__min_df': [1, 3, 5],             # frecuencia mínima de términos\n",
    "    'cnb__alpha': [0.1, 0.5, 1.0]           # suavizado\n",
    "}\n",
    "\n",
    "# Grid search con F1 macro\n",
    "grid = GridSearchCV(pipeline_cnb, param_grid, scoring='f1_macro', cv=3, n_jobs=-1)\n",
    "grid.fit(newsgroups_train.data, newsgroups_train.target)\n",
    "\n",
    "print(\"Mejores parámetros:\", grid.best_params_)\n",
    "print(\"Mejor F1-score (validación):\", grid.best_score_)\n",
    "\n",
    "# Evaluamos en el test final\n",
    "best_model = grid.best_estimator_\n",
    "y_pred_best = best_model.predict(newsgroups_test.data)\n",
    "print(\"F1-score (macro) en test con mejor modelo:\", f1_score(newsgroups_test.target, y_pred_best, average='macro'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3498b6",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "\n",
    "- Con MultinomialNB se obtuvo un F1-score de 0.585\n",
    "\n",
    "- Con ComplementNB se obtuvo un F1-score de 0.693\n",
    "\n",
    "- Con ComplementNB optimizado se obtuvo un F1-score de 0.710 en test, maximizando asi el desempeño."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad0954f",
   "metadata": {},
   "source": [
    "#### Parte 4\n",
    "#### Transponer la matriz documento–término para estudiar la similaridad entre palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b28400bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizamos de nuevo (usamos stopwords y min_df>2 para evitar palabras raras)\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", min_df=3)\n",
    "X = vectorizer.fit_transform(newsgroups_train.data)\n",
    "\n",
    "# Matriz término-documento en forma dispersa (NO convertimos a array denso)\n",
    "X_words = X.T  # sigue siendo sparse\n",
    "\n",
    "# Diccionario de palabras\n",
    "terms = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "153ba3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Palabra: god\n",
      "   jesus (0.277)\n",
      "   bible (0.273)\n",
      "   christ (0.267)\n",
      "   faith (0.258)\n",
      "   existence (0.253)\n",
      "\n",
      "Palabra: windows\n",
      "   dos (0.307)\n",
      "   ms (0.227)\n",
      "   microsoft (0.211)\n",
      "   nt (0.202)\n",
      "   file (0.192)\n",
      "\n",
      "Palabra: car\n",
      "   cars (0.193)\n",
      "   dealer (0.176)\n",
      "   civic (0.170)\n",
      "   owner (0.155)\n",
      "   loan (0.154)\n",
      "\n",
      "Palabra: space\n",
      "   nasa (0.325)\n",
      "   shuttle (0.283)\n",
      "   seds (0.279)\n",
      "   enfant (0.264)\n",
      "   exploration (0.237)\n",
      "\n",
      "Palabra: game\n",
      "   games (0.213)\n",
      "   espn (0.187)\n",
      "   hockey (0.182)\n",
      "   team (0.181)\n",
      "   scored (0.179)\n"
     ]
    }
   ],
   "source": [
    "# palabras a analizar\n",
    "words_to_check = [\"god\", \"windows\", \"car\", \"space\", \"game\"]\n",
    "\n",
    "for word in words_to_check:\n",
    "    if word in terms:\n",
    "        idx = np.where(terms == word)[0][0]\n",
    "        # calculamos similaridad SOLO de esa palabra con todas las demás\n",
    "        sim_scores = cosine_similarity(X_words[idx], X_words).flatten()\n",
    "        # ordenamos y tomamos las 5 más similares\n",
    "        top5_idx = sim_scores.argsort()[::-1][1:6]\n",
    "        print(f\"\\nPalabra: {word}\")\n",
    "        for i in top5_idx:\n",
    "            print(f\"   {terms[i]} ({sim_scores[i]:.3f})\")\n",
    "    else:\n",
    "        print(f\"\\nPalabra '{word}' no encontrada en el vocabulario\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e609da6",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "\n",
    "Los resultados tienen mucho sentido semántico:\n",
    "\n",
    "- god → jesus, bible, christ, faith → coherente con religión.\n",
    "\n",
    "- windows → dos, ms, microsoft, nt → todo del ecosistema Microsoft.\n",
    "\n",
    "- car → cars, dealer, civic, owner → coherente con autos.\n",
    "\n",
    "- space → nasa, shuttle, exploration → relacionado con exploración espacial.\n",
    "\n",
    "- game → games, espn, hockey, team → vinculado al deporte y juegos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Procesamiento Lenguaje Natural",
   "language": "python",
   "name": "procesamiento_lenguaje_natural"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
