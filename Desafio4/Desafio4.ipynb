{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifEj56Kh0O1E"
      },
      "source": [
        "# LSTM Traductor\n",
        "\n",
        "Replicar y extender el traductor:\n",
        "- Replicar el modelo en PyTorch.\n",
        "- Extender el entrenamiento a más datos y tamaños de\n",
        "secuencias mayores.\n",
        "- Explorar el impacto de la cantidad de neuronas en\n",
        "las capas recurrentes.\n",
        "- Mostrar 5 ejemplos de traducciones generadas.\n",
        "- Extras que se pueden probar: Embeddings\n",
        "pre-entrenados para los dos idiomas; cambiar la\n",
        "estrategia de generación (por ejemplo muestreo\n",
        "aleatorio);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLjWp51yHzwf"
      },
      "source": [
        "**1) librerias**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYcZXZB0EZF_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import torch\n",
        "import random\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import requests\n",
        "import gzip\n",
        "import shutil\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVmyCiOrE2te"
      },
      "source": [
        "**2) Descargar y preparar dataset spa-eng**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6zHYPzqE4up",
        "outputId": "6166ec08-9b32-4480-b587-e7330df18ef3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Descargando spa-eng.zip …\n",
            "Descomprimiendo …\n"
          ]
        }
      ],
      "source": [
        "dataset_zip = \"spa-eng.zip\"\n",
        "dataset_folder = \"spa-eng\"\n",
        "dataset_txt = os.path.join(dataset_folder, \"spa.txt\")\n",
        "if not os.path.exists(dataset_folder):\n",
        "    if not os.path.exists(dataset_zip):\n",
        "        print(\"Descargando spa-eng.zip …\")\n",
        "        urllib.request.urlretrieve(\"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\", dataset_zip)\n",
        "    print(\"Descomprimiendo …\")\n",
        "    with zipfile.ZipFile(dataset_zip, \"r\") as z:\n",
        "        z.extractall()\n",
        "else:\n",
        "    print(\"Dataset spa-eng ya presente\")\n",
        "\n",
        "assert os.path.exists(dataset_txt), \"No se encontró el archivo spa.txt después de la descarga.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxW4aIfaIPu-"
      },
      "source": [
        "**3) Lectura y preprocesamiento**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71o--TfVIRN7",
        "outputId": "1dfce569-e088-415b-bb52-fcf157c3e897"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de pares cargados: 118964\n",
            "Ejemplo: ('go.', 've.')\n"
          ]
        }
      ],
      "source": [
        "pairs = []\n",
        "with open(dataset_txt, encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        eng, spa = line.strip().split('\\t')[:2]\n",
        "        eng = eng.lower().strip()\n",
        "        spa = spa.lower().strip()\n",
        "        pairs.append((eng, spa))\n",
        "\n",
        "print(f\"Total de pares cargados: {len(pairs)}\")\n",
        "print(\"Ejemplo:\", pairs[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hE-vpZKITM2"
      },
      "source": [
        "**4) Tokenización y vocabularios**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZ0MqLQ4IVvb",
        "outputId": "de6a3667-ac7c-4db7-bd25-f2da02486c82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocab ENG: 8845\n",
            "Vocab ESP: 15254\n"
          ]
        }
      ],
      "source": [
        "def tokenize(text):\n",
        "    return re.findall(r'\\b\\w+\\b', text.lower())\n",
        "\n",
        "def build_vocab(sentences, min_freq=2):\n",
        "    vocab = {'<pad>': 0, '<sos>': 1, '<eos>': 2, '<unk>': 3}\n",
        "    freqs = {}\n",
        "    for s in sentences:\n",
        "        for w in tokenize(s):\n",
        "            freqs[w] = freqs.get(w, 0) + 1\n",
        "    for w, f in freqs.items():\n",
        "        if f >= min_freq:\n",
        "            vocab[w] = len(vocab)\n",
        "    return vocab\n",
        "\n",
        "eng_vocab = build_vocab([p[0] for p in pairs])\n",
        "spa_vocab = build_vocab([p[1] for p in pairs])\n",
        "\n",
        "print(\"Vocab ENG:\", len(eng_vocab))\n",
        "print(\"Vocab ESP:\", len(spa_vocab))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTmVZBgZIaRg"
      },
      "source": [
        "**5) Codificación y Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDEbYk6gIcm0"
      },
      "outputs": [],
      "source": [
        "def encode_sentence(sentence, vocab, max_len=20):\n",
        "    tokens = tokenize(sentence)\n",
        "    ids = [vocab.get(w, vocab['<unk>']) for w in tokens]\n",
        "    ids = [vocab['<sos>']] + ids[:max_len-2] + [vocab['<eos>']]\n",
        "    pad_len = max_len - len(ids)\n",
        "    ids += [vocab['<pad>']] * pad_len\n",
        "    return ids\n",
        "\n",
        "MAX_LEN = 20\n",
        "data = [(encode_sentence(e, eng_vocab, MAX_LEN),\n",
        "         encode_sentence(s, spa_vocab, MAX_LEN))\n",
        "        for e, s in pairs]\n",
        "\n",
        "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    def __getitem__(self, idx):\n",
        "        return (torch.tensor(self.data[idx][0]),\n",
        "                torch.tensor(self.data[idx][1]))\n",
        "\n",
        "train_loader = DataLoader(TranslationDataset(train_data), batch_size=64, shuffle=True)\n",
        "val_loader   = DataLoader(TranslationDataset(val_data), batch_size=64)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KObNEA_IjIn"
      },
      "source": [
        "**6) Carga de Embeddings (GloVe inglés, FastText español)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ngZE949ImmV",
        "outputId": "adb1d98f-4e3e-45fa-e2a8-1fffefcab120"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Descargando GloVe 300d (en inglés)...\n",
            "Descargando FastText español...\n",
            "Embeddings listos.\n"
          ]
        }
      ],
      "source": [
        "os.makedirs(\"embeddings\", exist_ok=True)\n",
        "\n",
        "# Descarga GloVe inglés\n",
        "glove_path = \"embeddings/glove.6B.300d.txt\"\n",
        "if not os.path.exists(glove_path):\n",
        "    print(\"Descargando GloVe 300d (en inglés)...\")\n",
        "    glove_zip = \"embeddings/glove.6B.zip\"\n",
        "    url = \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
        "    r = requests.get(url)\n",
        "    open(glove_zip, \"wb\").write(r.content)\n",
        "    with zipfile.ZipFile(glove_zip, \"r\") as zip_ref:\n",
        "        zip_ref.extract(\"glove.6B.300d.txt\", \"embeddings\")\n",
        "\n",
        "# Descarga FastText español\n",
        "fasttext_path = \"embeddings/cc.es.300.vec\"\n",
        "if not os.path.exists(fasttext_path):\n",
        "    print(\"Descargando FastText español...\")\n",
        "    url = \"https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.es.300.vec.gz\"\n",
        "    r = requests.get(url)\n",
        "    open(\"embeddings/cc.es.300.vec.gz\", \"wb\").write(r.content)\n",
        "    with gzip.open(\"embeddings/cc.es.300.vec.gz\", \"rb\") as f_in:\n",
        "        with open(fasttext_path, \"wb\") as f_out:\n",
        "            shutil.copyfileobj(f_in, f_out)\n",
        "\n",
        "print(\"Embeddings listos.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqdQ1WI0I2Ev"
      },
      "source": [
        "**7) Cargar los vectores a memoria**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKxQ4Z_yI5Ae",
        "outputId": "25cab94e-90b2-4f95-a819-ef33621944f4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cargando embeddings/glove.6B.300d.txt: 400000it [00:10, 36576.54it/s]\n",
            "Cargando embeddings/cc.es.300.vec: 2000001it [00:42, 47423.52it/s]\n"
          ]
        }
      ],
      "source": [
        "def load_embeddings(file_path, vocab, dim=300):\n",
        "    matrix = np.random.normal(scale=0.6, size=(len(vocab), dim))\n",
        "    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "        for line in tqdm(f, desc=f\"Cargando {file_path}\"):\n",
        "            parts = line.rstrip().split(' ')\n",
        "            if len(parts) <= dim:\n",
        "                continue\n",
        "            word = parts[0]\n",
        "            if word in vocab:\n",
        "                vec = np.asarray(parts[1:dim+1], dtype='float32')\n",
        "                matrix[vocab[word]] = vec\n",
        "    return torch.tensor(matrix, dtype=torch.float32)\n",
        "\n",
        "emb_eng = load_embeddings(glove_path, eng_vocab)\n",
        "emb_spa = load_embeddings(fasttext_path, spa_vocab)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaZkFM9VI7vn"
      },
      "source": [
        "**8) Modelo Encoder-Decoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gBLmORnI-Z1"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, embeddings):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(embeddings, freeze=True)\n",
        "        self.lstm = nn.LSTM(emb_dim, hidden_dim, batch_first=True)\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        outputs, (h, c) = self.lstm(x)\n",
        "        return h, c\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, embeddings):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(embeddings, freeze=True)\n",
        "        self.lstm = nn.LSTM(emb_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "    def forward(self, x, h, c):\n",
        "        x = self.embedding(x)\n",
        "        output, (h, c) = self.lstm(x, (h, c))\n",
        "        out = self.fc(output)\n",
        "        return out, h, c\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "        batch_size, trg_len = trg.shape\n",
        "        vocab_size = len(spa_vocab)\n",
        "        outputs = torch.zeros(batch_size, trg_len, vocab_size).to(self.device)\n",
        "        h, c = self.encoder(src)\n",
        "        x = trg[:, 0].unsqueeze(1)\n",
        "        for t in range(1, trg_len):\n",
        "            out, h, c = self.decoder(x, h, c)\n",
        "            outputs[:, t] = out.squeeze(1)\n",
        "            best = out.argmax(2)\n",
        "            x = trg[:, t].unsqueeze(1) if np.random.rand() < teacher_forcing_ratio else best\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NxtXZ-UK9vm"
      },
      "source": [
        "**9) Entrenamiento**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3oPFA-OLBdu"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def train_model(hidden_size, epochs=10):\n",
        "    print(f\"\\nEntrenando modelo con HIDDEN_SIZE = {hidden_size}\\n\")\n",
        "\n",
        "    encoder = Encoder(len(eng_vocab), EMBED_DIM, hidden_size, emb_eng)\n",
        "    decoder = Decoder(len(spa_vocab), EMBED_DIM, hidden_size, emb_spa)\n",
        "    model = Seq2Seq(encoder, decoder, DEVICE).to(DEVICE)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=spa_vocab['<pad>'])\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        for src, trg in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "            src, trg = src.to(DEVICE), trg.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(src, trg)\n",
        "            output_dim = output.shape[-1]\n",
        "            loss = criterion(output[:, 1:].reshape(-1, output_dim), trg[:, 1:].reshape(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1} | Loss: {epoch_loss/len(train_loader):.4f}\")\n",
        "\n",
        "    # Guardamos el modelo completo\n",
        "    model_path = f\"seq2seq_hidden{hidden_size}.pt\"\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    print(f\"Modelo guardado en: {model_path}\\n\")\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iySbOeHYRIR",
        "outputId": "f9d4d83a-a196-4c05-f15e-8e5f2f0e0c3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Entrenando modelo con HIDDEN_SIZE = 256\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10: 100%|██████████| 1488/1488 [02:42<00:00,  9.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Loss: 5.4048\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10: 100%|██████████| 1488/1488 [02:42<00:00,  9.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 | Loss: 4.3525\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10: 100%|██████████| 1488/1488 [02:41<00:00,  9.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 | Loss: 3.7351\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10: 100%|██████████| 1488/1488 [02:41<00:00,  9.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 | Loss: 3.2881\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10: 100%|██████████| 1488/1488 [02:43<00:00,  9.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 | Loss: 2.9540\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/10: 100%|██████████| 1488/1488 [02:41<00:00,  9.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 | Loss: 2.7023\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/10: 100%|██████████| 1488/1488 [02:40<00:00,  9.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 | Loss: 2.4910\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/10: 100%|██████████| 1488/1488 [02:41<00:00,  9.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 | Loss: 2.3190\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/10: 100%|██████████| 1488/1488 [02:43<00:00,  9.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 | Loss: 2.1831\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/10: 100%|██████████| 1488/1488 [02:43<00:00,  9.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 | Loss: 2.0540\n",
            "Modelo guardado en: seq2seq_hidden256.pt\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_256 = train_model(hidden_size=256, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVdR8gnEYVwh",
        "outputId": "dcfff525-640f-457f-82b3-3c29f9b5772b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Entrenando modelo con HIDDEN_SIZE = 512\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10: 100%|██████████| 1488/1488 [03:03<00:00,  8.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Loss: 5.2214\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10: 100%|██████████| 1488/1488 [03:04<00:00,  8.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 | Loss: 3.8036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10: 100%|██████████| 1488/1488 [03:03<00:00,  8.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 | Loss: 3.0549\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10: 100%|██████████| 1488/1488 [03:03<00:00,  8.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 | Loss: 2.5824\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10: 100%|██████████| 1488/1488 [03:04<00:00,  8.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 | Loss: 2.2335\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/10: 100%|██████████| 1488/1488 [03:03<00:00,  8.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 | Loss: 1.9647\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/10: 100%|██████████| 1488/1488 [03:03<00:00,  8.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 | Loss: 1.7601\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/10: 100%|██████████| 1488/1488 [03:03<00:00,  8.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 | Loss: 1.6033\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/10: 100%|██████████| 1488/1488 [03:04<00:00,  8.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 | Loss: 1.4635\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/10: 100%|██████████| 1488/1488 [03:02<00:00,  8.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 | Loss: 1.3562\n",
            "Modelo guardado en: seq2seq_hidden512.pt\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_512 = train_model(hidden_size=512, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqK7m_y9YWfB",
        "outputId": "9be0e870-470b-41e0-9074-c8ae5b80270d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Entrenando modelo con HIDDEN_SIZE = 1024\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10: 100%|██████████| 1488/1488 [04:06<00:00,  6.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Loss: 4.8830\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10: 100%|██████████| 1488/1488 [04:07<00:00,  6.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 | Loss: 3.2279\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10: 100%|██████████| 1488/1488 [04:07<00:00,  6.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 | Loss: 2.4786\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10: 100%|██████████| 1488/1488 [04:07<00:00,  6.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 | Loss: 1.9949\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10: 100%|██████████| 1488/1488 [04:06<00:00,  6.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 | Loss: 1.6579\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/10: 100%|██████████| 1488/1488 [04:07<00:00,  6.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 | Loss: 1.4066\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/10: 100%|██████████| 1488/1488 [04:07<00:00,  6.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 | Loss: 1.2138\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/10: 100%|██████████| 1488/1488 [04:07<00:00,  6.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 | Loss: 1.0576\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/10: 100%|██████████| 1488/1488 [04:07<00:00,  6.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 | Loss: 0.9405\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/10: 100%|██████████| 1488/1488 [04:07<00:00,  6.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 | Loss: 0.8354\n",
            "Modelo guardado en: seq2seq_hidden1024.pt\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_1024 = train_model(hidden_size=1024, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbe0O7ohLGd9"
      },
      "source": [
        "**10) Traducción (Inferencia)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJyTK5i1YPmq",
        "outputId": "78aca497-d2ca-4f56-f5ea-acc9f269d6bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "English: I love music.\n",
            "🔸 256 units: me encanta la música\n",
            "🔸 512 units: me encanta la música\n",
            "🔸 1024 units: me encanta el música\n",
            "\n",
            "English: This book is very interesting.\n",
            "🔸 256 units: este libro es muy interesante\n",
            "🔸 512 units: este libro es muy interesante\n",
            "🔸 1024 units: este libro es muy interesante\n",
            "\n",
            "English: I need help.\n",
            "🔸 256 units: necesito ayuda\n",
            "🔸 512 units: necesito ayuda\n",
            "🔸 1024 units: necesito ayuda\n",
            "\n",
            "English: Thanks for everything.\n",
            "🔸 256 units: gracias por todo\n",
            "🔸 512 units: gracias por todo\n",
            "🔸 1024 units: gracias por todo\n",
            "\n",
            "English: my mother calls me.\n",
            "🔸 256 units: mi madre me invitó\n",
            "🔸 512 units: mi madre me llamó\n",
            "🔸 1024 units: mi madre me llama\n",
            "\n",
            "English: You're very nice.\n",
            "🔸 256 units: eres muy bien\n",
            "🔸 512 units: eres muy bueno\n",
            "🔸 1024 units: eres muy simpático\n",
            "\n",
            "English: I need to go home.\n",
            "🔸 256 units: necesito irme a casa\n",
            "🔸 512 units: necesito ir a casa\n",
            "🔸 1024 units: necesito ir a casa\n",
            "\n",
            "English: I'm cleaning my room.\n",
            "🔸 256 units: estoy limpiando mi cuarto\n",
            "🔸 512 units: estoy limpiando mi habitación\n",
            "🔸 1024 units: estoy trapeando mi habitación\n",
            "\n",
            "English: This is very important.\n",
            "🔸 256 units: esto es muy importante\n",
            "🔸 512 units: esto es muy importante\n",
            "🔸 1024 units: esto es muy importante\n",
            "\n",
            "English: See you later.\n",
            "🔸 256 units: te veré\n",
            "🔸 512 units: te vemos luego\n",
            "🔸 1024 units: hasta luego\n"
          ]
        }
      ],
      "source": [
        "# Función de traducción\n",
        "def translate_sentence(sentence, model, max_len=MAX_LEN):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        src = torch.tensor(encode_sentence(sentence, eng_vocab, MAX_LEN)).unsqueeze(0).to(DEVICE)\n",
        "        h, c = model.encoder(src)\n",
        "        x = torch.tensor([[spa_vocab['<sos>']]]).to(DEVICE)\n",
        "        translated = []\n",
        "        for _ in range(max_len):\n",
        "            out, h, c = model.decoder(x, h, c)\n",
        "            pred = out.argmax(2)\n",
        "            token = pred.item()\n",
        "            if token == spa_vocab['<eos>']:\n",
        "                break\n",
        "            translated.append(token)\n",
        "            x = pred\n",
        "        inv_spa_vocab = {i: w for w, i in spa_vocab.items()}\n",
        "        return ' '.join([inv_spa_vocab.get(t, '?') for t in translated])\n",
        "\n",
        "\n",
        "# 🔹 Cargar modelos entrenados\n",
        "def load_model(hidden_size, model_path):\n",
        "    encoder = Encoder(len(eng_vocab), EMBED_DIM, hidden_size, emb_eng)\n",
        "    decoder = Decoder(len(spa_vocab), EMBED_DIM, hidden_size, emb_spa)\n",
        "    model = Seq2Seq(encoder, decoder, DEVICE).to(DEVICE)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "model_256 = load_model(256, \"seq2seq_hidden256.pt\")\n",
        "model_512 = load_model(512, \"seq2seq_hidden512.pt\")\n",
        "model_1024 = load_model(1024, \"seq2seq_hidden1024.pt\")\n",
        "\n",
        "# 🔹 Oraciones de prueba\n",
        "test_sentences = [\n",
        "    \"I love music.\",\n",
        "    \"This book is very interesting.\",\n",
        "    \"I need help.\",\n",
        "    \"Thanks for everything.\",\n",
        "    \"my mother calls me.\",\n",
        "    \"You're very nice.\",\n",
        "    \"I need to go home.\",\n",
        "    \"I'm cleaning my room.\",\n",
        "    \"This is very important.\",\n",
        "    \"See you later.\"\n",
        "]\n",
        "\n",
        "# 🔹 Comparar traducciones\n",
        "for s in test_sentences:\n",
        "    print(f\"\\nEnglish: {s}\")\n",
        "    print(f\"🔸 256 units: {translate_sentence(s, model_256)}\")\n",
        "    print(f\"🔸 512 units: {translate_sentence(s, model_512)}\")\n",
        "    print(f\"🔸 1024 units: {translate_sentence(s, model_1024)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Conclusiones**\n",
        "\n",
        "Calidad de las traducciones:\n",
        "\n",
        "Todos los modelos logran buenas traducciones, pero:\n",
        "\n",
        "- El modelo con 512 neuronas ofrece un balance ideal entre precisión y eficiencia, produciendo traducciones más naturales y fluidas.\n",
        "\n",
        "- El modelo con 1024 neuronas, aunque más preciso, a veces genera palabras contextualmente similares pero no tan exactas.\n",
        "\n",
        "- Aumento de hidden size mejora la calidad, pero incrementa el tiempo de entrenamiento."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
