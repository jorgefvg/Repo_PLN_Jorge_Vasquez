{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifEj56Kh0O1E"
      },
      "source": [
        "# LSTM Traductor\n",
        "\n",
        "Replicar y extender el traductor:\n",
        "- Replicar el modelo en PyTorch.\n",
        "- Extender el entrenamiento a m谩s datos y tama帽os de\n",
        "secuencias mayores.\n",
        "- Explorar el impacto de la cantidad de neuronas en\n",
        "las capas recurrentes.\n",
        "- Mostrar 5 ejemplos de traducciones generadas.\n",
        "- Extras que se pueden probar: Embeddings\n",
        "pre-entrenados para los dos idiomas; cambiar la\n",
        "estrategia de generaci贸n (por ejemplo muestreo\n",
        "aleatorio);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLjWp51yHzwf"
      },
      "source": [
        "**1) librerias**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYcZXZB0EZF_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import torch\n",
        "import random\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import requests\n",
        "import gzip\n",
        "import shutil\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVmyCiOrE2te"
      },
      "source": [
        "**2) Descargar y preparar dataset spa-eng**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6zHYPzqE4up",
        "outputId": "6166ec08-9b32-4480-b587-e7330df18ef3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Descargando spa-eng.zip \n",
            "Descomprimiendo \n"
          ]
        }
      ],
      "source": [
        "dataset_zip = \"spa-eng.zip\"\n",
        "dataset_folder = \"spa-eng\"\n",
        "dataset_txt = os.path.join(dataset_folder, \"spa.txt\")\n",
        "if not os.path.exists(dataset_folder):\n",
        "    if not os.path.exists(dataset_zip):\n",
        "        print(\"Descargando spa-eng.zip \")\n",
        "        urllib.request.urlretrieve(\"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\", dataset_zip)\n",
        "    print(\"Descomprimiendo \")\n",
        "    with zipfile.ZipFile(dataset_zip, \"r\") as z:\n",
        "        z.extractall()\n",
        "else:\n",
        "    print(\"Dataset spa-eng ya presente\")\n",
        "\n",
        "assert os.path.exists(dataset_txt), \"No se encontr贸 el archivo spa.txt despu茅s de la descarga.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxW4aIfaIPu-"
      },
      "source": [
        "**3) Lectura y preprocesamiento**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71o--TfVIRN7",
        "outputId": "1dfce569-e088-415b-bb52-fcf157c3e897"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de pares cargados: 118964\n",
            "Ejemplo: ('go.', 've.')\n"
          ]
        }
      ],
      "source": [
        "pairs = []\n",
        "with open(dataset_txt, encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        eng, spa = line.strip().split('\\t')[:2]\n",
        "        eng = eng.lower().strip()\n",
        "        spa = spa.lower().strip()\n",
        "        pairs.append((eng, spa))\n",
        "\n",
        "print(f\"Total de pares cargados: {len(pairs)}\")\n",
        "print(\"Ejemplo:\", pairs[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hE-vpZKITM2"
      },
      "source": [
        "**4) Tokenizaci贸n y vocabularios**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZ0MqLQ4IVvb",
        "outputId": "de6a3667-ac7c-4db7-bd25-f2da02486c82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocab ENG: 8845\n",
            "Vocab ESP: 15254\n"
          ]
        }
      ],
      "source": [
        "def tokenize(text):\n",
        "    return re.findall(r'\\b\\w+\\b', text.lower())\n",
        "\n",
        "def build_vocab(sentences, min_freq=2):\n",
        "    vocab = {'<pad>': 0, '<sos>': 1, '<eos>': 2, '<unk>': 3}\n",
        "    freqs = {}\n",
        "    for s in sentences:\n",
        "        for w in tokenize(s):\n",
        "            freqs[w] = freqs.get(w, 0) + 1\n",
        "    for w, f in freqs.items():\n",
        "        if f >= min_freq:\n",
        "            vocab[w] = len(vocab)\n",
        "    return vocab\n",
        "\n",
        "eng_vocab = build_vocab([p[0] for p in pairs])\n",
        "spa_vocab = build_vocab([p[1] for p in pairs])\n",
        "\n",
        "print(\"Vocab ENG:\", len(eng_vocab))\n",
        "print(\"Vocab ESP:\", len(spa_vocab))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTmVZBgZIaRg"
      },
      "source": [
        "**5) Codificaci贸n y Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDEbYk6gIcm0"
      },
      "outputs": [],
      "source": [
        "def encode_sentence(sentence, vocab, max_len=20):\n",
        "    tokens = tokenize(sentence)\n",
        "    ids = [vocab.get(w, vocab['<unk>']) for w in tokens]\n",
        "    ids = [vocab['<sos>']] + ids[:max_len-2] + [vocab['<eos>']]\n",
        "    pad_len = max_len - len(ids)\n",
        "    ids += [vocab['<pad>']] * pad_len\n",
        "    return ids\n",
        "\n",
        "MAX_LEN = 20\n",
        "data = [(encode_sentence(e, eng_vocab, MAX_LEN),\n",
        "         encode_sentence(s, spa_vocab, MAX_LEN))\n",
        "        for e, s in pairs]\n",
        "\n",
        "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    def __getitem__(self, idx):\n",
        "        return (torch.tensor(self.data[idx][0]),\n",
        "                torch.tensor(self.data[idx][1]))\n",
        "\n",
        "train_loader = DataLoader(TranslationDataset(train_data), batch_size=64, shuffle=True)\n",
        "val_loader   = DataLoader(TranslationDataset(val_data), batch_size=64)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KObNEA_IjIn"
      },
      "source": [
        "**6) Carga de Embeddings (GloVe ingl茅s, FastText espa帽ol)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ngZE949ImmV",
        "outputId": "adb1d98f-4e3e-45fa-e2a8-1fffefcab120"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Descargando GloVe 300d (en ingl茅s)...\n",
            "Descargando FastText espa帽ol...\n",
            "Embeddings listos.\n"
          ]
        }
      ],
      "source": [
        "os.makedirs(\"embeddings\", exist_ok=True)\n",
        "\n",
        "# Descarga GloVe ingl茅s\n",
        "glove_path = \"embeddings/glove.6B.300d.txt\"\n",
        "if not os.path.exists(glove_path):\n",
        "    print(\"Descargando GloVe 300d (en ingl茅s)...\")\n",
        "    glove_zip = \"embeddings/glove.6B.zip\"\n",
        "    url = \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
        "    r = requests.get(url)\n",
        "    open(glove_zip, \"wb\").write(r.content)\n",
        "    with zipfile.ZipFile(glove_zip, \"r\") as zip_ref:\n",
        "        zip_ref.extract(\"glove.6B.300d.txt\", \"embeddings\")\n",
        "\n",
        "# Descarga FastText espa帽ol\n",
        "fasttext_path = \"embeddings/cc.es.300.vec\"\n",
        "if not os.path.exists(fasttext_path):\n",
        "    print(\"Descargando FastText espa帽ol...\")\n",
        "    url = \"https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.es.300.vec.gz\"\n",
        "    r = requests.get(url)\n",
        "    open(\"embeddings/cc.es.300.vec.gz\", \"wb\").write(r.content)\n",
        "    with gzip.open(\"embeddings/cc.es.300.vec.gz\", \"rb\") as f_in:\n",
        "        with open(fasttext_path, \"wb\") as f_out:\n",
        "            shutil.copyfileobj(f_in, f_out)\n",
        "\n",
        "print(\"Embeddings listos.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqdQ1WI0I2Ev"
      },
      "source": [
        "**7) Cargar los vectores a memoria**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKxQ4Z_yI5Ae",
        "outputId": "25cab94e-90b2-4f95-a819-ef33621944f4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cargando embeddings/glove.6B.300d.txt: 400000it [00:10, 36576.54it/s]\n",
            "Cargando embeddings/cc.es.300.vec: 2000001it [00:42, 47423.52it/s]\n"
          ]
        }
      ],
      "source": [
        "def load_embeddings(file_path, vocab, dim=300):\n",
        "    matrix = np.random.normal(scale=0.6, size=(len(vocab), dim))\n",
        "    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "        for line in tqdm(f, desc=f\"Cargando {file_path}\"):\n",
        "            parts = line.rstrip().split(' ')\n",
        "            if len(parts) <= dim:\n",
        "                continue\n",
        "            word = parts[0]\n",
        "            if word in vocab:\n",
        "                vec = np.asarray(parts[1:dim+1], dtype='float32')\n",
        "                matrix[vocab[word]] = vec\n",
        "    return torch.tensor(matrix, dtype=torch.float32)\n",
        "\n",
        "emb_eng = load_embeddings(glove_path, eng_vocab)\n",
        "emb_spa = load_embeddings(fasttext_path, spa_vocab)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaZkFM9VI7vn"
      },
      "source": [
        "**8) Modelo Encoder-Decoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gBLmORnI-Z1"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, embeddings):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(embeddings, freeze=True)\n",
        "        self.lstm = nn.LSTM(emb_dim, hidden_dim, batch_first=True)\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        outputs, (h, c) = self.lstm(x)\n",
        "        return h, c\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, embeddings):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(embeddings, freeze=True)\n",
        "        self.lstm = nn.LSTM(emb_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "    def forward(self, x, h, c):\n",
        "        x = self.embedding(x)\n",
        "        output, (h, c) = self.lstm(x, (h, c))\n",
        "        out = self.fc(output)\n",
        "        return out, h, c\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "        batch_size, trg_len = trg.shape\n",
        "        vocab_size = len(spa_vocab)\n",
        "        outputs = torch.zeros(batch_size, trg_len, vocab_size).to(self.device)\n",
        "        h, c = self.encoder(src)\n",
        "        x = trg[:, 0].unsqueeze(1)\n",
        "        for t in range(1, trg_len):\n",
        "            out, h, c = self.decoder(x, h, c)\n",
        "            outputs[:, t] = out.squeeze(1)\n",
        "            best = out.argmax(2)\n",
        "            x = trg[:, t].unsqueeze(1) if np.random.rand() < teacher_forcing_ratio else best\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NxtXZ-UK9vm"
      },
      "source": [
        "**9) Entrenamiento**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3oPFA-OLBdu"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def train_model(hidden_size, epochs=10):\n",
        "    print(f\"\\nEntrenando modelo con HIDDEN_SIZE = {hidden_size}\\n\")\n",
        "\n",
        "    encoder = Encoder(len(eng_vocab), EMBED_DIM, hidden_size, emb_eng)\n",
        "    decoder = Decoder(len(spa_vocab), EMBED_DIM, hidden_size, emb_spa)\n",
        "    model = Seq2Seq(encoder, decoder, DEVICE).to(DEVICE)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=spa_vocab['<pad>'])\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        for src, trg in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "            src, trg = src.to(DEVICE), trg.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(src, trg)\n",
        "            output_dim = output.shape[-1]\n",
        "            loss = criterion(output[:, 1:].reshape(-1, output_dim), trg[:, 1:].reshape(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1} | Loss: {epoch_loss/len(train_loader):.4f}\")\n",
        "\n",
        "    # Guardamos el modelo completo\n",
        "    model_path = f\"seq2seq_hidden{hidden_size}.pt\"\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    print(f\"Modelo guardado en: {model_path}\\n\")\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iySbOeHYRIR",
        "outputId": "f9d4d83a-a196-4c05-f15e-8e5f2f0e0c3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Entrenando modelo con HIDDEN_SIZE = 256\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10: 100%|| 1488/1488 [02:42<00:00,  9.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Loss: 5.4048\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10: 100%|| 1488/1488 [02:42<00:00,  9.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 | Loss: 4.3525\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10: 100%|| 1488/1488 [02:41<00:00,  9.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 | Loss: 3.7351\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10: 100%|| 1488/1488 [02:41<00:00,  9.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 | Loss: 3.2881\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10: 100%|| 1488/1488 [02:43<00:00,  9.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 | Loss: 2.9540\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/10: 100%|| 1488/1488 [02:41<00:00,  9.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 | Loss: 2.7023\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/10: 100%|| 1488/1488 [02:40<00:00,  9.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 | Loss: 2.4910\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/10: 100%|| 1488/1488 [02:41<00:00,  9.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 | Loss: 2.3190\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/10: 100%|| 1488/1488 [02:43<00:00,  9.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 | Loss: 2.1831\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/10: 100%|| 1488/1488 [02:43<00:00,  9.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 | Loss: 2.0540\n",
            "Modelo guardado en: seq2seq_hidden256.pt\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_256 = train_model(hidden_size=256, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVdR8gnEYVwh",
        "outputId": "dcfff525-640f-457f-82b3-3c29f9b5772b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Entrenando modelo con HIDDEN_SIZE = 512\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10: 100%|| 1488/1488 [03:03<00:00,  8.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Loss: 5.2214\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10: 100%|| 1488/1488 [03:04<00:00,  8.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 | Loss: 3.8036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10: 100%|| 1488/1488 [03:03<00:00,  8.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 | Loss: 3.0549\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10: 100%|| 1488/1488 [03:03<00:00,  8.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 | Loss: 2.5824\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10: 100%|| 1488/1488 [03:04<00:00,  8.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 | Loss: 2.2335\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/10: 100%|| 1488/1488 [03:03<00:00,  8.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 | Loss: 1.9647\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/10: 100%|| 1488/1488 [03:03<00:00,  8.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 | Loss: 1.7601\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/10: 100%|| 1488/1488 [03:03<00:00,  8.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 | Loss: 1.6033\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/10: 100%|| 1488/1488 [03:04<00:00,  8.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 | Loss: 1.4635\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/10: 100%|| 1488/1488 [03:02<00:00,  8.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 | Loss: 1.3562\n",
            "Modelo guardado en: seq2seq_hidden512.pt\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_512 = train_model(hidden_size=512, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqK7m_y9YWfB",
        "outputId": "9be0e870-470b-41e0-9074-c8ae5b80270d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Entrenando modelo con HIDDEN_SIZE = 1024\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10: 100%|| 1488/1488 [04:06<00:00,  6.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Loss: 4.8830\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10: 100%|| 1488/1488 [04:07<00:00,  6.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 | Loss: 3.2279\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10: 100%|| 1488/1488 [04:07<00:00,  6.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 | Loss: 2.4786\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10: 100%|| 1488/1488 [04:07<00:00,  6.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 | Loss: 1.9949\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10: 100%|| 1488/1488 [04:06<00:00,  6.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 | Loss: 1.6579\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/10: 100%|| 1488/1488 [04:07<00:00,  6.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 | Loss: 1.4066\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/10: 100%|| 1488/1488 [04:07<00:00,  6.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 | Loss: 1.2138\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/10: 100%|| 1488/1488 [04:07<00:00,  6.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 | Loss: 1.0576\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/10: 100%|| 1488/1488 [04:07<00:00,  6.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 | Loss: 0.9405\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/10: 100%|| 1488/1488 [04:07<00:00,  6.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 | Loss: 0.8354\n",
            "Modelo guardado en: seq2seq_hidden1024.pt\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_1024 = train_model(hidden_size=1024, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbe0O7ohLGd9"
      },
      "source": [
        "**10) Traducci贸n (Inferencia)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJyTK5i1YPmq",
        "outputId": "78aca497-d2ca-4f56-f5ea-acc9f269d6bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "English: I love music.\n",
            " 256 units: me encanta la m煤sica\n",
            " 512 units: me encanta la m煤sica\n",
            " 1024 units: me encanta el m煤sica\n",
            "\n",
            "English: This book is very interesting.\n",
            " 256 units: este libro es muy interesante\n",
            " 512 units: este libro es muy interesante\n",
            " 1024 units: este libro es muy interesante\n",
            "\n",
            "English: I need help.\n",
            " 256 units: necesito ayuda\n",
            " 512 units: necesito ayuda\n",
            " 1024 units: necesito ayuda\n",
            "\n",
            "English: Thanks for everything.\n",
            " 256 units: gracias por todo\n",
            " 512 units: gracias por todo\n",
            " 1024 units: gracias por todo\n",
            "\n",
            "English: my mother calls me.\n",
            " 256 units: mi madre me invit贸\n",
            " 512 units: mi madre me llam贸\n",
            " 1024 units: mi madre me llama\n",
            "\n",
            "English: You're very nice.\n",
            " 256 units: eres muy bien\n",
            " 512 units: eres muy bueno\n",
            " 1024 units: eres muy simp谩tico\n",
            "\n",
            "English: I need to go home.\n",
            " 256 units: necesito irme a casa\n",
            " 512 units: necesito ir a casa\n",
            " 1024 units: necesito ir a casa\n",
            "\n",
            "English: I'm cleaning my room.\n",
            " 256 units: estoy limpiando mi cuarto\n",
            " 512 units: estoy limpiando mi habitaci贸n\n",
            " 1024 units: estoy trapeando mi habitaci贸n\n",
            "\n",
            "English: This is very important.\n",
            " 256 units: esto es muy importante\n",
            " 512 units: esto es muy importante\n",
            " 1024 units: esto es muy importante\n",
            "\n",
            "English: See you later.\n",
            " 256 units: te ver茅\n",
            " 512 units: te vemos luego\n",
            " 1024 units: hasta luego\n"
          ]
        }
      ],
      "source": [
        "# Funci贸n de traducci贸n\n",
        "def translate_sentence(sentence, model, max_len=MAX_LEN):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        src = torch.tensor(encode_sentence(sentence, eng_vocab, MAX_LEN)).unsqueeze(0).to(DEVICE)\n",
        "        h, c = model.encoder(src)\n",
        "        x = torch.tensor([[spa_vocab['<sos>']]]).to(DEVICE)\n",
        "        translated = []\n",
        "        for _ in range(max_len):\n",
        "            out, h, c = model.decoder(x, h, c)\n",
        "            pred = out.argmax(2)\n",
        "            token = pred.item()\n",
        "            if token == spa_vocab['<eos>']:\n",
        "                break\n",
        "            translated.append(token)\n",
        "            x = pred\n",
        "        inv_spa_vocab = {i: w for w, i in spa_vocab.items()}\n",
        "        return ' '.join([inv_spa_vocab.get(t, '?') for t in translated])\n",
        "\n",
        "\n",
        "#  Cargar modelos entrenados\n",
        "def load_model(hidden_size, model_path):\n",
        "    encoder = Encoder(len(eng_vocab), EMBED_DIM, hidden_size, emb_eng)\n",
        "    decoder = Decoder(len(spa_vocab), EMBED_DIM, hidden_size, emb_spa)\n",
        "    model = Seq2Seq(encoder, decoder, DEVICE).to(DEVICE)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "model_256 = load_model(256, \"seq2seq_hidden256.pt\")\n",
        "model_512 = load_model(512, \"seq2seq_hidden512.pt\")\n",
        "model_1024 = load_model(1024, \"seq2seq_hidden1024.pt\")\n",
        "\n",
        "#  Oraciones de prueba\n",
        "test_sentences = [\n",
        "    \"I love music.\",\n",
        "    \"This book is very interesting.\",\n",
        "    \"I need help.\",\n",
        "    \"Thanks for everything.\",\n",
        "    \"my mother calls me.\",\n",
        "    \"You're very nice.\",\n",
        "    \"I need to go home.\",\n",
        "    \"I'm cleaning my room.\",\n",
        "    \"This is very important.\",\n",
        "    \"See you later.\"\n",
        "]\n",
        "\n",
        "#  Comparar traducciones\n",
        "for s in test_sentences:\n",
        "    print(f\"\\nEnglish: {s}\")\n",
        "    print(f\" 256 units: {translate_sentence(s, model_256)}\")\n",
        "    print(f\" 512 units: {translate_sentence(s, model_512)}\")\n",
        "    print(f\" 1024 units: {translate_sentence(s, model_1024)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Conclusiones**\n",
        "\n",
        "Calidad de las traducciones:\n",
        "\n",
        "Todos los modelos logran buenas traducciones, pero:\n",
        "\n",
        "- El modelo con 512 neuronas ofrece un balance ideal entre precisi贸n y eficiencia, produciendo traducciones m谩s naturales y fluidas.\n",
        "\n",
        "- El modelo con 1024 neuronas, aunque m谩s preciso, a veces genera palabras contextualmente similares pero no tan exactas.\n",
        "\n",
        "- Aumento de hidden size mejora la calidad, pero incrementa el tiempo de entrenamiento."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
